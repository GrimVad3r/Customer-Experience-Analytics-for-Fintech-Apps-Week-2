# üì± Ethiopian Mobile Banking App Review Scraper and Preprocessor

This repository contains two Python scripts designed to **scrape** customer reviews for Ethiopian mobile banking applications from the Google Play Store and subsequently **preprocess** the collected raw data for analysis.

---

## üöÄ Overview

The workflow is divided into two main stages:

1.  **`scrapper.py`**: Uses the `google-play-scraper` library to fetch app reviews based on a provided list of app IDs.
2.  **`Pre_Processor.py`**: Cleans the raw scraped data by selecting relevant columns, standardizing column names, handling missing values, and removing duplicates.

---

## üõ†Ô∏è Prerequisites

To run these scripts, you will need **Python 3.x** and the following libraries:

* `pandas`
* `google-play-scraper`

You can install the necessary dependencies using pip:

```bash
pip install pandas google-play-scraper

üìÅ scrapper.py
This script handles the web scraping of app reviews.

Key Functions
scrape_reviews(app_name, app_id, count=400):

Purpose: Scrapes a specified number of recent reviews for a single application ID.

Details: It retrieves reviews sorted by newest for the specified app_id, targeting the English language (lang='en') and Ethiopia (country='et').

run_scraper(APPS, count=500, output_file='../data/bank_reviews_raw.csv'):

Purpose: The main execution function that iterates through a dictionary of apps, scrapes their reviews, validates the total count, and saves the raw data.

Input (APPS): A dictionary mapping bank names to their Google Play Store app IDs.

Python

APPS = {
    'CBE':'com.combanketh.mobilebanking',
    'Awash Bank': 'com.sc.awashpay',
    'Abyssinia Bank':'com.boa.boaMobileBanking'
}
Output: Saves the concatenated raw reviews to the specified output_file.

Usage
Define your target applications in the APPS dictionary.

Call the run_scraper function.

Python

# Example in a main script file:
from scrapper import run_scraper

# Define the apps to scrape
TARGET_APPS = {
    'Bank A':'com.bankA.app',
    'Bank B': 'com.bankB.app',
}

# Run the scraping process
raw_data_df = run_scraper(APPS=TARGET_APPS, count=1000, output_file='path/to/my_raw_reviews.csv')
üßº Pre_Processor.py
This script takes the raw data produced by scrapper.py and cleans it for analysis.

Key Function
preprocess_data(df, output_file='../data/bank_reviews_clean.csv'):

Purpose: Cleans and standardizes the raw reviews DataFrame.

Steps:

Column Selection & Rename: Keeps only content, score, at, bank, and source. Renames them to review, rating, date, bank, and source.

Date Formatting: Converts the date column to a date-only format.

Missing Data: Removes rows where the review content is missing (dropna).

Deduplication: Removes duplicate entries based on the combination of review, date, and bank.

Input: A raw pandas DataFrame (df).

Output: Saves the cleaned DataFrame to the specified output_file.

Usage
Read the raw CSV file generated by scrapper.py into a pandas DataFrame.

Call the preprocess_data function.

Python

# Example in a main script file:
from Pre_Processor import preprocess_data
import pandas as pd

# Load the raw data (assuming it's already scraped and saved)
raw_df = pd.read_csv('../data/bank_reviews_raw.csv')

# Run the preprocessing step
clean_data_df = preprocess_data(raw_df, output_file='path/to/my_clean_reviews.csv')